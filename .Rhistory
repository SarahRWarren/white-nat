text_clean) %>%
select(user,
time,
date,
word,
id) %>%
anti_join(stop_words)
#Add the word stemmed words.
unigram <- unigram %>%
mutate(word_stem = wordStem(word),
word_stem = ifelse(word == 'baby' | word == 'mother' | word == 'pregnant',
as.character(word),
word_stem))
#Create a word count dataframe
unigram_count <- unigram %>%
count(word, sort = T) %>%
mutate(word = reorder(word, n)) %>%
mutate(word_stem = wordStem(word),
word_stem = ifelse(word == 'baby' | word == 'mother' | word == 'pregnant',
word,
word_stem))
bigram <- ladies %>%
mutate(text_clean = str_replace_all(text_nopunct,
"[Nn]ational\\s[Ss]ocialism[A-z]*",
"ns") %>%
str_replace_all("[Nn]ational\\s[Ss]ocialist[A-z]*",
"ns") %>%
str_replace_all("[Pp]regnant[A-z]*",
"pregnant") %>%
str_replace_all("[Hh]itlers*",
"hitler") %>%
str_replace_all("[A-z]*[Mm]ein(\\s)*[Kk]ampf[A-z]*",
"meinkampf") %>%
str_replace_all("[Nn]ationalis[tm]",
"national") %>%
str_replace_all("[A-z]*([Tt]hird|3rd)(\\s)*[Rr]eich[A-z]*",
"3rd_reich") %>%
str_replace_all("[Nn]azi",
"nazi") %>%
rm_stopwords(Top200Words,
separate = FALSE)) %>%
unnest_tokens(bigram,
text_clean,
token = "ngrams",
n = 2) %>%
select(user,
time,
date,
bigram,
id)
library(Rcpp)
library(Rcpp)
install.packages("Rcpp")
install.packages("Rcpp")
install.packages("Rcpp")
library(tidyverse)
library(SnowballC)
library(tidytext)
library(qdap)
library(Rcpp)
data('Top200Words')
ladies <- read_rds("data/ladies.Rds")
unigram <- ladies %>%
mutate(text_clean = str_replace_all(text_nopunct,
"[Nn]ational\\s[Ss]ocialism[A-z]*",
"ns") %>%
str_replace_all("[Nn]ational\\s[Ss]ocialist[A-z]*",
"ns") %>%
str_replace_all("[Pp]regnant[A-z]*",
"pregnant") %>%
str_replace_all("[Hh]itlers*",
"hitler") %>%
str_replace_all("[A-z]*[Mm]ein(\\s)*[Kk]ampf[A-z]*",
"meinkampf") %>%
str_replace_all("[Nn]ationalis[tm]",
"national") %>%
str_replace_all("[A-z]*([Tt]hird|3rd)(\\s)*[Rr]eich[A-z]*",
"3rd_reich") %>%
str_replace_all("[Nn]azi",
"nazi")) %>%
unnest_tokens(word,
text_clean) %>%
select(user,
time,
date,
word,
id) %>%
anti_join(stop_words)
#Add the word stemmed words.
unigram <- unigram %>%
mutate(word_stem = wordStem(word),
word_stem = ifelse(word == 'baby' | word == 'mother' | word == 'pregnant',
as.character(word),
word_stem))
#Create a word count dataframe
unigram_count <- unigram %>%
count(word, sort = T) %>%
mutate(word = reorder(word, n)) %>%
mutate(word_stem = wordStem(word),
word_stem = ifelse(word == 'baby' | word == 'mother' | word == 'pregnant',
word,
word_stem))
bigram <- ladies %>%
mutate(text_clean = str_replace_all(text_nopunct,
"[Nn]ational\\s[Ss]ocialism[A-z]*",
"ns") %>%
str_replace_all("[Nn]ational\\s[Ss]ocialist[A-z]*",
"ns") %>%
str_replace_all("[Pp]regnant[A-z]*",
"pregnant") %>%
str_replace_all("[Hh]itlers*",
"hitler") %>%
str_replace_all("[A-z]*[Mm]ein(\\s)*[Kk]ampf[A-z]*",
"meinkampf") %>%
str_replace_all("[Nn]ationalis[tm]",
"national") %>%
str_replace_all("[A-z]*([Tt]hird|3rd)(\\s)*[Rr]eich[A-z]*",
"3rd_reich") %>%
str_replace_all("[Nn]azi",
"nazi") %>%
rm_stopwords(Top200Words,
separate = FALSE)) %>%
unnest_tokens(bigram,
text_clean,
token = "ngrams",
n = 2) %>%
select(user,
time,
date,
bigram,
id)
bigram_split <- bigram %>%
separate(bigram, c("word1",
"word2"),
sep = " ",
remove = F) %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word1 %in% stop_words$word) %>%
filter(!is.na(bigram)) %>%
count(bigram, sort = T) %>%
mutate(bigram = reorder(bigram, n))
#Count the frequency of bigrams and order them by frequency.
bigram_sorted <- bigram %>%
count(bigram, sort = T) %>%
mutate(bigram = reorder(bigram, n))
View(bigram_sorted)
View(bigram_split)
View(bigram_sorted)
ggplot(bigram_sorted, aes(x=bigram, y=n)) + geom_col() + coord_flip()
View(bigram_sorted)
ggplot(bigram_sorted, aes(x=bigram, y=n)) + geom_col() + coord_flip() +
theme_bw()
bigram_sorted <- bigram_sorted %>%
mutate(n=n_freq)
bigram_sorted <- bigram_sorted %>%
mutate(n=rename(n_freq))
rename(bigram_sorted, n_freq = n)
View(bigram_sorted)
bigram_sorted$n <- rename(bigram_sorted, n_freq = n)
View(bigram_sorted)
bigram_sorted <- rename(bigram_sorted, n_freq = n)
View(bigram_sorted)
bigram_sorted <- bigram %>%
count(bigram, sort = T) %>%
mutate(bigram = reorder(bigram, n))
bigram_sorted <- rename(bigram_sorted, n_freq = n)
View(bigram_sorted)
ggplot(bigram_sorted, aes(x=bigram, y=n_freq)) + geom_col() + coord_flip() +
theme_bw()
detach("package:Rcpp", unload = TRUE)
ggplot(bigram_sorted, aes(x=n_freq, y=bigram)) + geom_col() +
theme_bw()
View(bigram_sorted)
ggplot(bigram_sorted, aes(x=n_freq, y=bigram)) + geom_col() +
theme_bw() +
theme(axis.text = element_text(size=2.5)) +
scale_x_continuous(limit=c(0,3400),
breaks = c(0, 100, 200, 300, 400, 500, 600, 700,
800, 900, 1000, 1100, 1200, 1300, 1400,
1500, 1600, 1700, 1800, 1900, 2000, 2100,
2200, 2300, 2400, 2500, 2600, 2700,
2800, 2900, 3000, 3100, 3200, 3300,
3400),
expand = c(0,0)) +
labs(title = "Bigrams in Ladies Forum",
x= "Frequency",
y="")
ggsave("figs/bigram_sorted_ladies.png", height = 20)
more_than_once <- bigram_sorted %>%
subset(n_freq > 1)
ggplot(more_than_once, aes(x=n_freq, y=bigram)) + geom_col() +
theme_bw() +
theme(axis.text = element_text(size=2.5)) +
labs(title = "Bigrams in Ladies Forum",
x= "Frequency",
y="")
ggsave("figs/bigram_sorted_ladies.png", height = 20)
summary(more_than_once$n_freq)
bigrams_selected <- bigram_sorted %>%
subset(n_freq > 5) ##mean is 4.2, so bigrams that occur more frequently than the mean frequency
ggplot(bigrams_selected, aes(x=n_freq, y=bigram)) + geom_col() +
theme_bw() +
theme(axis.text = element_text(size=2.5)) +
labs(title = "Bigrams in Ladies Forum",
x= "Frequency",
y="")
ggplot(bigrams_selected, aes(x=n_freq, y=bigram)) + geom_col() +
theme_bw() +
theme(axis.text = element_text(size=2.5)) +
scale_x_continuous(expand = c(0,0)) +
labs(title = "Bigrams in Ladies Forum",
x= "Frequency",
y="")
ggsave("figs/bigram_sorted_ladies.png", height = 20)
bigrams_selected <- bigram_sorted %>%
subset(n_freq > 100)
View(bigrams_selected)
bigram <- ladies %>%
mutate(text_clean = str_replace_all(text_nopunct,
"[Nn]ational\\s[Ss]ocialism[A-z]*",
"ns") %>%
str_replace_all("[Nn]ational\\s[Ss]ocialist[A-z]*",
"ns") %>%
str_replace_all("[Pp]regnant[A-z]*",
"pregnant") %>%
str_replace_all("[Pp]regnancy\\s[Tt]read[A-z]*",
"pregnancy thread") %>%
str_replace_all("[A-z]*[Mm]ein(\\s)*[Kk]ampf[A-z]*",
"meinkampf") %>%
str_replace_all("[Nn]ationalis[tm]",
"national") %>%
str_replace_all("[A-z]*([Tt]hird|3rd)(\\s)*[Rr]eich[A-z]*",
"3rd_reich") %>%
str_replace_all("[Nn]azi",
"nazi") %>%
rm_stopwords(Top200Words,
separate = FALSE)) %>%
unnest_tokens(bigram,
text_clean,
token = "ngrams",
n = 2) %>%
select(user,
time,
date,
bigram,
id)
bigram_split <- bigram %>%
separate(bigram, c("word1",
"word2"),
sep = " ",
remove = F) %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word1 %in% stop_words$word) %>%
filter(!is.na(bigram)) %>%
count(bigram, sort = T) %>%
mutate(bigram = reorder(bigram, n))
bigram_sorted <- bigram %>%
count(bigram, sort = T) %>%
mutate(bigram = reorder(bigram, n))
bigram_sorted <- rename(bigram_sorted, n_freq = n)
bigrams_selected <- bigram_sorted %>%
subset(n_freq > 100)
View(bigrams_selected)
bigram <- ladies %>%
mutate(text_clean = str_replace_all(text_nopunct,
"[Nn]ational\\s[Ss]ocialism[A-z]*",
"ns") %>%
str_replace_all("[Nn]ational\\s[Ss]ocialist[A-z]*",
"ns") %>%
str_replace_all("[Pp]regnant[A-z]*",
"pregnant") %>%
str_replace_all("[Pp]regnant\\s[Tt]read[A-z]*",
"pregnant thread") %>%
str_replace_all("[A-z]*[Mm]ein(\\s)*[Kk]ampf[A-z]*",
"meinkampf") %>%
str_replace_all("[Nn]ationalis[tm]",
"national") %>%
str_replace_all("[A-z]*([Tt]hird|3rd)(\\s)*[Rr]eich[A-z]*",
"3rd_reich") %>%
str_replace_all("[Nn]azi",
"nazi") %>%
rm_stopwords(Top200Words,
separate = FALSE)) %>%
unnest_tokens(bigram,
text_clean,
token = "ngrams",
n = 2) %>%
select(user,
time,
date,
bigram,
id)
#Use the tidytext way on the stop-word-removed data using the qdap approach. Similar Results.
bigram_split <- bigram %>%
separate(bigram, c("word1",
"word2"),
sep = " ",
remove = F) %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word1 %in% stop_words$word) %>%
filter(!is.na(bigram)) %>%
count(bigram, sort = T) %>%
mutate(bigram = reorder(bigram, n))
#Count the frequency of bigrams and order them by frequency.
bigram_sorted <- bigram %>%
count(bigram, sort = T) %>%
mutate(bigram = reorder(bigram, n))
bigram_sorted <- rename(bigram_sorted, n_freq = n)
bigrams_selected <- bigram_sorted %>%
subset(n_freq > 100)
View(bigrams_selected)
library(tidyverse)
library(SnowballC)
library(tidytext)
library(qdap)
library(Rcpp)
data('Top200Words')
ladies <- read_rds("data/ladies.Rds")
unigram <- ladies %>%
mutate(text_clean = str_replace_all(text_nopunct,
"[Nn]ational\\s[Ss]ocialism[A-z]*",
"ns") %>%
str_replace_all("[Nn]ational\\s[Ss]ocialist[A-z]*",
"ns") %>%
str_replace_all("[Pp]regnant[A-z]*",
"pregnant") %>%
str_replace_all("[Hh]itlers*",
"hitler") %>%
str_replace_all("[A-z]*[Mm]ein(\\s)*[Kk]ampf[A-z]*",
"meinkampf") %>%
str_replace_all("[Nn]ationalis[tm]",
"national") %>%
str_replace_all("[A-z]*([Tt]hird|3rd)(\\s)*[Rr]eich[A-z]*",
"3rd_reich") %>%
str_replace_all("[Nn]azi",
"nazi")) %>%
unnest_tokens(word,
text_clean) %>%
select(user,
time,
date,
word,
id) %>%
anti_join(stop_words)
#Add the word stemmed words.
unigram <- unigram %>%
mutate(word_stem = wordStem(word),
word_stem = ifelse(word == 'baby' | word == 'mother' | word == 'pregnant',
as.character(word),
word_stem))
#Create a word count dataframe
unigram_count <- unigram %>%
count(word, sort = T) %>%
mutate(word = reorder(word, n)) %>%
mutate(word_stem = wordStem(word),
word_stem = ifelse(word == 'baby' | word == 'mother' | word == 'pregnant',
word,
word_stem))
unigram_sorted <- unigram %>%
count(unigram, sort = T) %>%
mutate(unigram = reorder(unigram, n))
View(unigram)
unigram_sorted <- unigram %>%
count(word, sort = T) %>%
mutate(unigram = reorder(word, n))
View(unigram_sorted)
unigram_sorted <- unigram %>%
count(word, sort = T) %>%
mutate(word = reorder(word, n))
View(unigram_sorted)
ladies <- read_rds("data/ladies.Rds")
unigram <- ladies %>%
mutate(text_clean = str_replace_all(text_nopunct,
"[Nn]ational\\s[Ss]ocialism[A-z]*",
"ns") %>%
str_replace_all("[Nn]ational\\s[Ss]ocialist[A-z]*",
"ns") %>%
str_replace_all("[Pp]regnant[A-z]*",
"pregnant") %>%
str_replace_all("[Hh]itlers*",
"hitler") %>%
str_replace_all("[A-z]*[Mm]ein(\\s)*[Kk]ampf[A-z]*",
"meinkampf") %>%
str_replace_all("[Nn]ationalis[tm]",
"national") %>%
str_replace_all("[A-z]*([Tt]hird|3rd)(\\s)*[Rr]eich[A-z]*",
"3rd_reich") %>%
str_replace_all("[Nn]azi",
"nazi")) %>%
unnest_tokens(word,
text_clean) %>%
select(user,
time,
date,
word,
id) %>%
anti_join(stop_words)
unigram_count <- unigram %>%
count(word, sort = T) %>%
mutate(word = reorder(word, n)) %>%
mutate(word_stem = wordStem(word),
word_stem = ifelse(word == 'baby' | word == 'mother' | word == 'pregnant',
word,
word_stem))
###sort
unigram_sorted <- unigram %>%
count(word, sort = T) %>%
mutate(word = reorder(word, n))
View(unigram_sorted)
View(unigram_sorted)
unigram_200 <- unigram_sorted %>%
select(n >= 98)
unigram_200 <- unigram_sorted %>%
subset(n >= 98)
unigram_sorted <- unigram %>%
count(word, sort = T) %>%
mutate(word = reorder(word, n_freq))
unigram_sorted <- unigram %>%
count(word, sort = T) %>%
mutate(word = reorder(word, n))
unigram_200 <- unigram_sorted %>%
subset(n >= 98)
ggplot(unigram_200, aes(x=word, y=n)) + geom_col() + theme_bw()
ggplot(unigram_200, aes(x=n, y=word)) + geom_col() + theme_bw()
ggplot(unigram_200, aes(x=n, y=word)) + geom_col() + theme_bw() +
scale_x_continuous(expand = c(0,0)) +
theme(axis.text = element_text(size=5))
ggplot(unigram_200, aes(x=n, y=word)) + geom_col() + theme_bw() +
scale_x_continuous(expand = c(0,0)) +
theme(axis.text = element_text(size=5)) +
labs(title = "Word Frequency on Women's Forums",
x= "Freqeuncy",
y="")
ggsave("figs/unigram_ladies_200.png", height=12)
ggsave("figs/unigram_ladies_200.png", height=12, width = 12)
View(unigram_200)
ggplot(unigram_200, aes(x=n, y=word)) + geom_col() + theme_bw() +
scale_x_continuous(limit=c(0,4000),
breaks = c(0, 100, 150, 200, 250, 300, 400, 500,
600, 700, 800, 900, 1000,
1100, 1200, 1300, 1400, 1500,
2000, 3000, 3500),
expand = c(0,0)) +
theme(axis.text = element_text(size=5)) +
labs(title = "Word Frequency on Women's Forums",
x= "Freqeuncy",
y="")
ggplot(unigram_200, aes(x=n, y=word)) + geom_col() + theme_bw() +
scale_x_continuous(limit=c(0,4000),
breaks = c(0, 100, 150, 200, 250, 300, 400, 500,
600, 700, 800, 900, 1000,
1100, 1200, 1300, 1400, 1500,
2000, 3000, 3500),
expand = c(0,0)) +
theme(axis.text = element_text(size=5, angle = 90)) +
labs(title = "Word Frequency on Women's Forums",
x= "Freqeuncy",
y="")
ggsave("figs/unigram_ladies_200.png", height=12, width = 12)
ggsave("figs/unigram_ladies_200.png", height=12, width = 12)
ggplot(unigram_200, aes(x=n, y=word)) + geom_col() + theme_bw() +
scale_x_continuous(limit=c(0,4000),
breaks = c(0, 100, 150, 200, 250, 300, 400, 500,
600, 700, 800, 900, 1000,
1100, 1200, 1300, 1400, 1500,
2000, 3000, 3500),
expand = c(0,0)) +
theme(axis.text = element_text(size=5)) +
theme(axis.text.x = element_text(angle = 90)) +
labs(title = "Word Frequency on Women's Forums",
x= "Freqeuncy",
y="")
ggsave("figs/unigram_ladies_200.png", height=12, width = 12)
ggplot(unigram_200, aes(x=n, y=word, fill=n)) + geom_col() + theme_bw() +
scale_x_continuous(limit=c(0,4000),
breaks = c(0, 100, 150, 200, 250, 300, 400, 500,
600, 700, 800, 900, 1000,
1100, 1200, 1300, 1400, 1500,
2000, 3000, 3500),
expand = c(0,0)) +
theme(axis.text = element_text(size=5)) +
theme(axis.text.x = element_text(angle = 90)) +
labs(title = "Word Frequency on Women's Forums",
x= "Freqeuncy",
y="")
ggplot(unigram_200, aes(x=n, y=word, fill=n)) + geom_col() + theme_bw() +
scale_x_continuous(limit=c(0,4000),
breaks = c(0, 100, 150, 200, 250, 300, 400, 500,
600, 700, 800, 900, 1000,
1100, 1200, 1300, 1400, 1500,
2000, 3000, 3500),
expand = c(0,0)) +
theme(axis.text = element_text(size=5)) +
theme(axis.text.x = element_text(angle = 90)) +
labs(title = "Word Frequency on Women's Forums",
x= "Freqeuncy",
y="",
fill = Frequency (High-Low))
ggplot(unigram_200, aes(x=n, y=word, fill=n)) + geom_col() + theme_bw() +
scale_x_continuous(limit=c(0,4000),
breaks = c(0, 100, 150, 200, 250, 300, 400, 500,
600, 700, 800, 900, 1000,
1100, 1200, 1300, 1400, 1500,
2000, 3000, 3500),
expand = c(0,0)) +
theme(axis.text = element_text(size=5)) +
theme(axis.text.x = element_text(angle = 90)) +
labs(title = "Word Frequency on Women's Forums",
x= "Freqeuncy",
y="",
fill = "Frequency (High-Low)")
ggsave("figs/unigram_ladies_200.png", height=12, width = 12)
